{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### DATA PREPROCESSING\n",
        "\n",
        "Download Santali speech dataset from [IndicVoices Website](https://indicvoices.ai4bharat.org/)\n",
        "\n",
        "###### INDICVOICE DATASET\n",
        "This 1639 houred dataset from 16237 speakers covers 145 Indian districts and 22 languages. Despite significant progress in English ASR, advancements in mid- and low-resource languages remain limited due to the lack of diverse, high-quality labeled data. The study targets data collection for 22 Indian languages, which represent 1.2 billion speakers across 742 districts, considering their linguistic, cultural, and demographic diversity. A repository of 2.5K questions, 46.6K prompts, and 1.1K–4.1K role-play scenarios were chosen in 21 domains and 28 topics to build this versatile dataset. A dedicated quality control team and a multi-level transcription team were employed to ensure strict adherence to guidelines.\n",
        "\n",
        "For detailed data collection methodology and transcription guidelines, kindly refer their [publication](https://arxiv.org/pdf/2403.01926)\n",
        "\n",
        "IndicVoices provided the test and the validation dataset, each of which contains several audio files in the `.wav` format and their corresponding metadata in the `.json` file. The JSON file contained information such as **duration**, **scenario**, and other details about the person, including their **job** and **qualification**. The JSON file also contained several dialogues, both in the verbatim as well as the normalized form. These two fields included the text, speaker_id, start and end timestamps.\n",
        "\n",
        "We will use the normalized data for our speech recognition task. Let's first extract audio chunks from this source.\n",
        "\n",
        "- Up/Down sampling\n",
        "- Reducing audio channels to one\n",
        "- Audio files chunking\n",
        "- SNR filtering\n",
        "- Manifest creation\n",
        "\n",
        "Some points to keep in mind about the audio files for wav2vec fine-tuning:\n",
        "- **Audio Format:** WAV, PCM 16-bit, mono (single channel).  \n",
        "- **Sampling Rate:** 16,000 Hz.  \n",
        "- **Duration:** Each audio file should be between 5 and 30 seconds long.  \n",
        "- **Content Guidelines:** Silence must be removed, and each file should feature only one speaker.  \n",
        "\n",
        "\n",
        "The folder structure should in a format like this.\n",
        "```\n",
        "datasets\n",
        "   ├── santali\n",
        "   │   ├── test\n",
        "   │   │   ├── audio\n",
        "   |   |   |    |──── 00001.wav\n",
        "   |   |   |    |──── 00002.wav\n",
        "   │   │   └── transcript.txt\n",
        "   │   ├── train\n",
        "   │   │   ├── audio\n",
        "   │   │   └── transcript.txt\n",
        "   │   └── valid\n",
        "   │       ├── audio\n",
        "   │       └── transcript.txt\n",
        "   └── hindi\n",
        "       ├── test\n",
        "       │   ├── audio\n",
        "       │   └── transcript.txt\n",
        "       ├── train\n",
        "       │   ├── audio\n",
        "       │   └── transcript.txt\n",
        "       └── valid\n",
        "           ├── audio\n",
        "           └── transcript.txt\n",
        "```\n"
      ],
      "metadata": {
        "id": "qP6afhlqELJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset"
      ],
      "metadata": {
        "id": "UpW91UTo0tn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Things to consider while writing transcript\n",
        "\n",
        "- The entire text should be transformed into uppercase.\n",
        "- Any numerical digits in the text should be converted into their corresponding word form.\n",
        "- All special characters, including punctuation marks, should be removed from the text.\n",
        "- Words should be separated by single spaces, with no extra spaces between them."
      ],
      "metadata": {
        "id": "RPfaIoq5H_k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "  #Remove all the non-Santali characters\n",
        "  vocab = \" ᱚᱛᱜᱝᱞᱟᱠᱡᱢᱣᱤᱥᱦᱧᱨᱩᱪᱫᱬᱭᱮᱯᱰᱱᱲᱳᱴᱵᱶᱷ᱐᱑᱒᱓᱔᱕᱖᱗᱘᱙\"\n",
        "  filtered_text = ''.join(char for char in text if char in vocab)\n",
        "\n",
        "  #convert numbers to words\n",
        "\n",
        "  # remove extra spaces\n",
        "  return ' '.join(filtered_text.split())"
      ],
      "metadata": {
        "id": "R9p7HH4QF5jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "2Tk1hrNf1BNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def process_audio_files(input_folder, output_folder, transcription_file):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Open the transcription file for writing\n",
        "    with open(transcription_file, 'w', encoding='utf-8') as transcription:\n",
        "        file_count = 1  # Counter for output filenames\n",
        "\n",
        "        # Walk through directories and subdirectories\n",
        "        for root, _, files in os.walk(input_folder):\n",
        "            for file in files:\n",
        "                if file.endswith(\".json\"):\n",
        "                    # Get the corresponding .wav file\n",
        "                    base_name = os.path.splitext(file)[0]\n",
        "                    wav_file = os.path.join(root, base_name + \".wav\")\n",
        "                    json_file = os.path.join(root, file)\n",
        "\n",
        "                    # Check if the .wav file exists\n",
        "                    if not os.path.exists(wav_file):\n",
        "                        print(f\"Warning: Audio file {wav_file} not found for {json_file}.\")\n",
        "                        continue\n",
        "\n",
        "                    # Load the JSON metadata\n",
        "                    with open(json_file, 'r', encoding='utf-8') as json_fp:\n",
        "                        metadata = json.load(json_fp)\n",
        "\n",
        "                    # Load the audio file\n",
        "                    audio = AudioSegment.from_wav(wav_file)\n",
        "\n",
        "                    # Process each segment in the \"normalized\" field\n",
        "                    for segment in metadata.get(\"normalized\", []):\n",
        "                        start = int(segment[\"start\"] * 1000)  # Convert to milliseconds\n",
        "                        end = int(segment[\"end\"] * 1000)  # Convert to milliseconds\n",
        "                        text = segment[\"text\"]\n",
        "\n",
        "                        # Clean/normalize text\n",
        "                        text = clean(text)\n",
        "\n",
        "                        # Split the audio segment\n",
        "                        audio_segment = audio[start:end]\n",
        "\n",
        "                        # Generate the new filename\n",
        "                        new_filename = f\"{file_count:05d}.wav\"\n",
        "                        new_filepath = os.path.join(output_folder, new_filename)\n",
        "\n",
        "                        # Export the audio segment\n",
        "                        audio_segment.export(new_filepath, format=\"wav\")\n",
        "\n",
        "                        # Write to the transcription file\n",
        "                        transcription.write(f\"{new_filename}\\t{text}\\n\")\n",
        "\n",
        "                        # Increment the file counter\n",
        "                        file_count += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_folder = \"path_to_input_folder\"  # Replace with the path to your input folder\n",
        "    output_folder = \"path_to_output_folder\"  # Replace with the path to your output folder\n",
        "    transcription_file = os.path.join(output_folder, \"transcription.txt\")\n",
        "\n",
        "    process_audio_files(input_folder, output_folder, transcription_file)"
      ],
      "metadata": {
        "id": "7LnNBvZs0vqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Creating manifest file\n",
        "The manifest file serves as a structured index or catalog of the dataset, providing the paths to audio files and their corresponding labels or transcripts."
      ],
      "metadata": {
        "id": "Fpmh1qDiqk6b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJvVa9oTD93j"
      },
      "outputs": [],
      "source": [
        "#Code credits - https://github.com/AI4Bharat/IndicWav2Vec/tree/main\n",
        "\n",
        "import soundfile as sf\n",
        "import glob\n",
        "import os,tqdm\n",
        "\n",
        "p2root = /path/to/root/folder/  #/content/datasets/santali in the example above\n",
        "\n",
        "manifest = p2root+\"/manifest/\"\n",
        "\n",
        "if not os.path.exists(manifest):\n",
        "    os.makedirs(manifest)\n",
        "\n",
        "charset = set()\n",
        "for folder in tqdm.tqdm(os.listdir(p2root)):\n",
        "    if 'manifest' == folder:\n",
        "        continue\n",
        "    wavs = glob.glob(p2root+'/'+folder+'/**/*.wav',recursive=True)\n",
        "    samples = [len(sf.read(w)[0]) for w in wavs]\n",
        "    #print(wavs)\n",
        "    root = os.path.abspath(os.path.split(wavs[0])[0])\n",
        "    wavs = [os.path.split(x)[-1] for x in wavs]\n",
        "\n",
        "    wav2trans = dict()\n",
        "\n",
        "    with open(p2root+'/'+folder+'/transcription.txt','r') as transcrip:\n",
        "        lines = transcrip.read().strip().split('\\n')\n",
        "    for line in lines:\n",
        "        if '\\t' in line:\n",
        "            file, trans = line.split(\"\\t\")\n",
        "        else:\n",
        "            splitted_line = line.split(\" \")\n",
        "            file, trans = splitted_line[0], \" \".join(splitted_line[1:])\n",
        "        wav2trans[file] = trans\n",
        "        charset.update(trans.replace(\" \",\"|\"))\n",
        "\n",
        "\n",
        "    with open(manifest+folder+\".tsv\",'w') as tsv, \\\n",
        "        open(manifest+folder+\".wrd\",\"w\") as wrd, \\\n",
        "        open(manifest+folder+\".ltr\",'w') as ltr:\n",
        "        print(root,file=tsv)\n",
        "        for n,d in zip(wavs,samples):\n",
        "            print(n,d,sep='\\t',file=tsv)\n",
        "            print(wav2trans[n[:-4]],file=wrd)\n",
        "            print(\" \".join(list(wav2trans[n[:-4]].replace(\" \", \"|\"))) + \" |\", file=ltr)\n",
        "\n",
        "\n",
        "with open(manifest+\"dict.ltr.txt\",'w') as dct:\n",
        "    for e,c in enumerate(charset):\n",
        "        print(c,e,file=dct)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Normalize the dataset\n"
      ],
      "metadata": {
        "id": "GmMAe2GGr_l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "path=\"/content/datasets\"  # Input directory path\n",
        "ext=\".mp3\"  # Input file extension (e.g., mp3)\n",
        "\n",
        "# Iterate through all files with the given extension\n",
        "for f in $(find \"$path\" -type f -name \"*$ext\"); do\n",
        "  # Get the file path without the original extension\n",
        "  output_file=\"${f%$ext}.wav\"\n",
        "\n",
        "  # Convert to .wav with 16 kHz and single channel\n",
        "  ffmpeg -loglevel warning -hide_banner -stats -i \"$f\" -ar 16000 -ac 1 \"$output_file\" && rm \"$f\" &\n",
        "\n",
        "done"
      ],
      "metadata": {
        "id": "Vr0TKIq3sF4c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}